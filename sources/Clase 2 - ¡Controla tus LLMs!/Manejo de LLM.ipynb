{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "intro-section"
      },
      "source": [
        "# üß† Tutorial 2: Google ADK - ¬°Controla tus LLMs!\n",
        "\n",
        "## LiteLLM, Par√°metros y Output Estructurado\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/)\n",
        "\n",
        "### üìã ¬øQu√© aprender√°s en este tutorial?\n",
        "\n",
        "1. **üîÑ Flexibilidad de Modelos con LiteLLM**\n",
        "   - Usar Claude, GPT, Llama y otros modelos en ADK\n",
        "   - Configuraci√≥n de m√∫ltiples proveedores\n",
        "\n",
        "2. **‚öôÔ∏è Ajustar el Comportamiento del LLM**\n",
        "   - Par√°metros clave: temperature, top_p, max_tokens\n",
        "   - Casos de uso para diferentes configuraciones\n",
        "\n",
        "3. **üìä Output Estructurado con Pydantic**\n",
        "   - Definir esquemas de datos\n",
        "   - Obtener respuestas JSON predecibles\n",
        "\n",
        "4. **üöÄ Ejemplos Pr√°cticos y Avanzados**\n",
        "   - Comparaci√≥n entre modelos\n",
        "   - Extracci√≥n de informaci√≥n compleja\n",
        "\n",
        "---\n",
        "\n",
        "### üéØ Objetivo del Tutorial\n",
        "\n",
        "Despu√©s de completar este tutorial, ser√°s capaz de:\n",
        "- Integrar cualquier LLM en tus agentes ADK\n",
        "- Ajustar finamente el comportamiento de los modelos\n",
        "- Obtener respuestas estructuradas y validadas\n",
        "\n",
        "**Requisitos previos:**\n",
        "- Haber completado el Tutorial 1 de ADK\n",
        "- API Keys de los modelos que quieras usar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup-section"
      },
      "source": [
        "## üîß Configuraci√≥n Inicial\n",
        "\n",
        "### Instalaci√≥n de Dependencias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install-dependencies"
      },
      "outputs": [],
      "source": [
        "# Instalar Google ADK con soporte para LiteLLM\n",
        "print(\"üì¶ Instalando Google ADK con LiteLLM...\")\n",
        "!pip install -q google-adk==1.4.2\n",
        "!pip install -q litellm==1.73.0\n",
        "!pip install -qU python-dotenv pydantic\n",
        "\n",
        "print(\"\\n‚úÖ Instalaci√≥n completada!\")\n",
        "\n",
        "# Verificar versiones\n",
        "import sys\n",
        "print(f\"\\nüêç Python: {sys.version.split()[0]}\")\n",
        "!pip show google-adk litellm pydantic | grep -E \"Name:|Version:\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "api-keys-section"
      },
      "source": [
        "### Configuraci√≥n de API Keys\n",
        "\n",
        "Para este tutorial, necesitar√°s al menos una API Key. Puedes obtenerlas de:\n",
        "- **Google AI Studio**: [https://aistudio.google.com/apikey](https://aistudio.google.com/apikey)\n",
        "- **Anthropic (Claude)**: [https://console.anthropic.com/](https://console.anthropic.com/)\n",
        "- **OpenAI**: [https://platform.openai.com/](https://platform.openai.com/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Opcion 1: Ingresalas directamente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "configure-api-keys"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîë Configuraci√≥n de API Keys\n",
            "\n",
            "Ingresa las API Keys que tengas disponibles (presiona Enter para omitir):\n",
            "\n",
            "\n",
            "üìã Estado de las API Keys:\n",
            "   Google: ‚úÖ\n",
            "   Anthropic: ‚úÖ\n",
            "   OpenAI: ‚úÖ\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "print(\"üîë Configuraci√≥n de API Keys\\n\")\n",
        "print(\"Ingresa las API Keys que tengas disponibles (presiona Enter para omitir):\\n\")\n",
        "\n",
        "# Google API Key (requerida para ejemplos base)\n",
        "if 'GOOGLE_API_KEY' not in os.environ:\n",
        "    google_key = getpass(\"Google API Key (requerida): \")\n",
        "    if google_key:\n",
        "        os.environ['GOOGLE_API_KEY'] = google_key\n",
        "        os.environ['GOOGLE_GENAI_USE_VERTEXAI'] = 'FALSE'\n",
        "\n",
        "# Anthropic API Key (opcional)\n",
        "if 'ANTHROPIC_API_KEY' not in os.environ:\n",
        "    anthropic_key = getpass(\"Anthropic API Key (opcional): \")\n",
        "    if anthropic_key:\n",
        "        os.environ['ANTHROPIC_API_KEY'] = anthropic_key\n",
        "\n",
        "# OpenAI API Key (opcional)\n",
        "if 'OPENAI_API_KEY' not in os.environ:\n",
        "    openai_key = getpass(\"OpenAI API Key (opcional): \")\n",
        "    if openai_key:\n",
        "        os.environ['OPENAI_API_KEY'] = openai_key\n",
        "\n",
        "# Verificar configuraci√≥n\n",
        "print(\"\\nüìã Estado de las API Keys:\")\n",
        "print(f\"   Google: {'‚úÖ' if os.environ.get('GOOGLE_API_KEY') else '‚ùå'}\")\n",
        "print(f\"   Anthropic: {'‚úÖ' if os.environ.get('ANTHROPIC_API_KEY') else '‚ùå'}\")\n",
        "print(f\"   OpenAI: {'‚úÖ' if os.environ.get('OPENAI_API_KEY') else '‚ùå'}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Opcion 2: Usar dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "# Cargar variables de entorno desde .env si existe\n",
        "load_dotenv(override=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "litellm-intro"
      },
      "source": [
        "## üîÑ Parte 1: Flexibilidad de Modelos con LiteLLM\n",
        "\n",
        "### ¬øQu√© es LiteLLM?\n",
        "\n",
        "LiteLLM es una biblioteca que proporciona una interfaz unificada para m√°s de 100 modelos de lenguaje diferentes. Act√∫a como un \"traductor universal\" entre ADK y los diversos proveedores de LLMs.\n",
        "\n",
        "### Ventajas de usar LiteLLM:\n",
        "\n",
        "- üß™ **Experimentaci√≥n f√°cil**: Prueba diferentes modelos sin cambiar tu c√≥digo\n",
        "- üí∞ **Optimizaci√≥n de costos**: Elige el modelo m√°s econ√≥mico para cada tarea\n",
        "- üîì **Sin vendor lock-in**: Libertad para cambiar de proveedor\n",
        "- üéØ **Modelos especializados**: Usa el mejor modelo para cada caso"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "create-agents-section"
      },
      "source": [
        "### Crear Agentes con Diferentes Modelos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.adk.runners import Runner\n",
        "from google.adk.sessions import InMemorySessionService\n",
        "from google.adk.agents.llm_agent import LlmAgent\n",
        "from google.genai import types\n",
        "\n",
        "\n",
        "async def call_agent_async(query: str, runner, user_id, session_id):\n",
        "    \"\"\"Env√≠a una consulta al agente e imprime la respuesta final.\"\"\"\n",
        "    print(f\"\\n>>> Consulta del usuario: {query}\")\n",
        "\n",
        "    # Prepara el mensaje del usuario en el formato de ADK\n",
        "    content = types.Content(role='user', parts=[types.Part(text=query)])\n",
        "\n",
        "    final_response_text = \"El agente no produjo una respuesta final.\" # Valor por defecto\n",
        "\n",
        "    # Concepto clave: run_async ejecuta la l√≥gica del agente y genera eventos.\n",
        "    # Iteramos a trav√©s de los eventos para encontrar la respuesta final.\n",
        "    async for event in runner.run_async(user_id=user_id, session_id=session_id, new_message=content):\n",
        "        # Puedes descomentar la l√≠nea de abajo para ver *todos* los eventos durante la ejecuci√≥n\n",
        "        # print(f\"  [Evento] Autor: {event.author}, Tipo: {type(event).__name__}, Final: {event.is_final_response()}, Contenido: {event.content}\")\n",
        "\n",
        "        # Concepto clave: is_final_response() marca el mensaje que concluye el turno.\n",
        "        if event.is_final_response():\n",
        "            if event.content and event.content.parts:\n",
        "                # Se asume que la respuesta de texto est√° en la primera parte\n",
        "                final_response_text = event.content.parts[0].text\n",
        "            elif event.actions and event.actions.escalate: # Maneja posibles errores/escalamientos\n",
        "                final_response_text = f\"El agente escal√≥: {event.error_message or 'Sin mensaje espec√≠fico.'}\"\n",
        "            # Agrega m√°s validaciones aqu√≠ si es necesario (por ejemplo, c√≥digos de error espec√≠ficos)\n",
        "            break # Deja de procesar eventos una vez encontrada la respuesta final\n",
        "\n",
        "    print(f\"<<< Respuesta del agente: {final_response_text}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Primero Gemimi de Google"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "MODEL_GEMINI = \"gemini-2.5-flash\"\n",
        "\n",
        "# Example: Defining the basic Agent\n",
        "refranes_agent = LlmAgent(\n",
        "    model=MODEL_GEMINI,\n",
        "    name=\"refranes_agent\",\n",
        "    description=\"completa los refranes que el usuario empieza\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "session_service = InMemorySessionService()\n",
        "\n",
        "APP_NAME = \"test_gemini\"\n",
        "USER_ID = \"user_1\"\n",
        "SESSION_ID = \"session_001\" # Using a fixed ID for simplicity\n",
        "\n",
        "# Create the specific session where the conversation will happen\n",
        "session = await session_service.create_session(app_name=APP_NAME,user_id=USER_ID,session_id=SESSION_ID)\n",
        "# Runner: This is the main component that manages the interaction with the agent.\n",
        "runner_gemini = Runner(agent=refranes_agent,app_name=APP_NAME,session_service=session_service)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            ">>> Consulta del usuario: A caballo regalado...\n",
            "<<< Respuesta del agente: A caballo regalado no se le mira el diente.\n"
          ]
        }
      ],
      "source": [
        "await call_agent_async(\"A caballo regalado...\",\n",
        "                           runner=runner_gemini,\n",
        "                           user_id=USER_ID,\n",
        "                           session_id=SESSION_ID)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Vamos con OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.adk.models.lite_llm import LiteLlm\n",
        "openai_model = LiteLlm(\"openai/gpt-4.1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "refranes_agent_openai = LlmAgent(\n",
        "    model=openai_model,\n",
        "    name=\"refranes_agent\",\n",
        "    description=\"completa los refranes que el usuario empieza\",\n",
        ")\n",
        "\n",
        "APP_NAME = \"test_openai\"\n",
        "USER_ID = \"user_2\"\n",
        "SESSION_ID = \"session_002\" # Using a fixed ID for simplicity\n",
        "\n",
        "session = await session_service.create_session(app_name=APP_NAME,user_id=USER_ID,session_id=SESSION_ID)\n",
        "runner_openai = Runner(agent=refranes_agent_openai,app_name=APP_NAME,session_service=session_service)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            ">>> Consulta del usuario: Camaron que se duerme...\n",
            "<<< Respuesta del agente: ...se lo lleva la corriente.\n"
          ]
        }
      ],
      "source": [
        "await call_agent_async(\"Camaron que se duerme...\",\n",
        "                           runner=runner_openai,\n",
        "                           user_id=USER_ID,\n",
        "                           session_id=SESSION_ID)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Probemos Anthropic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "anthropic_model = LiteLlm(\"anthropic/claude-3-7-sonnet-20250219\")\n",
        "refranes_agent_claude = LlmAgent(\n",
        "    model=anthropic_model,\n",
        "    name=\"refranes_agent\",\n",
        "    description=\"completa los refranes que el usuario empieza\",\n",
        ")\n",
        "\n",
        "APP_NAME = \"test_claude\"\n",
        "USER_ID = \"user_3\"\n",
        "SESSION_ID = \"session_003\" # Using a fixed ID for simplicity\n",
        "\n",
        "session = await session_service.create_session(app_name=APP_NAME,user_id=USER_ID,session_id=SESSION_ID)\n",
        "runner_openai = Runner(agent=refranes_agent_claude,app_name=APP_NAME,session_service=session_service)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            ">>> Consulta del usuario: Arbol que nace torcido...\n",
            "<<< Respuesta del agente: √Årbol que nace torcido, nunca su tronco endereza.\n",
            "\n",
            "Este refr√°n sugiere que cuando algo o alguien desarrolla ciertos h√°bitos o caracter√≠sticas desde el principio, es muy dif√≠cil cambiarlos m√°s adelante. Se refiere a la importancia de la educaci√≥n y formaci√≥n temprana en el desarrollo de una persona.\n",
            "\n",
            "¬øTe gustar√≠a que te complete alg√∫n otro refr√°n?\n"
          ]
        }
      ],
      "source": [
        "await call_agent_async(\"Arbol que nace torcido...\",\n",
        "                           runner=runner_openai,\n",
        "                           user_id=USER_ID,\n",
        "                           session_id=SESSION_ID)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Incluso con Azure - OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "azure_model = LiteLlm(\"azure/gpt-4o\")\n",
        "refranes_agent_azure = LlmAgent(\n",
        "    model=azure_model,\n",
        "    name=\"refranes_agent\",\n",
        "    description=\"completa los refranes que el usuario empieza\",\n",
        ")\n",
        "\n",
        "APP_NAME = \"test_azure\"\n",
        "USER_ID = \"user_4\"\n",
        "SESSION_ID = \"session_004\" # Using a fixed ID for simplicity\n",
        "\n",
        "\n",
        "session = await session_service.create_session(app_name=APP_NAME,user_id=USER_ID,session_id=SESSION_ID)\n",
        "runner_openai = Runner(agent=refranes_agent_azure,app_name=APP_NAME,session_service=session_service)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            ">>> Consulta del usuario: Escoba nueva...\n",
            "<<< Respuesta del agente: ¬°barre bien!\n"
          ]
        }
      ],
      "source": [
        "await call_agent_async(\"Escoba nueva...\",\n",
        "                           runner=runner_openai,\n",
        "                           user_id=USER_ID,\n",
        "                           session_id=SESSION_ID)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Incluso modelos locales"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "ollama_model = LiteLlm(\"ollama/gemma3:4b\")\n",
        "refranes_agent_ollama = LlmAgent(\n",
        "    model=ollama_model,\n",
        "    name=\"refranes_agent\",\n",
        "    description=\"completa los refranes que el usuario empieza\",\n",
        ")\n",
        "\n",
        "APP_NAME = \"test_ollama\"\n",
        "USER_ID = \"user_5\"\n",
        "SESSION_ID = \"session_005\" # Using a fixed ID for simplicity\n",
        "\n",
        "\n",
        "session = await session_service.create_session(app_name=APP_NAME,user_id=USER_ID,session_id=SESSION_ID)\n",
        "runner_openai = Runner(agent=refranes_agent_ollama,app_name=APP_NAME,session_service=session_service)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            ">>> Consulta del usuario: mas vale pajaro en mano...\n",
            "<<< Respuesta del agente: mas vale p√°jaro en mano, que mil volando.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "await call_agent_async(\"mas vale pajaro en mano...\",\n",
        "                        runner=runner_openai,\n",
        "                        user_id=USER_ID,\n",
        "                        session_id=SESSION_ID)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "parameters-intro"
      },
      "source": [
        "## ‚öôÔ∏è Parte 2: Ajustando el Comportamiento con Par√°metros\n",
        "\n",
        "### Par√°metros Clave de los LLMs\n",
        "\n",
        "Los par√°metros permiten controlar c√≥mo los modelos generan texto:\n",
        "\n",
        "1. **üå°Ô∏è Temperature (0.0 - 2.0)**\n",
        "   - Baja (0.0-0.3): Respuestas deterministas y conservadoras\n",
        "   - Media (0.4-0.7): Balance entre consistencia y creatividad\n",
        "   - Alta (0.8-2.0): Respuestas creativas y diversas\n",
        "\n",
        "2. **üéØ Top-p (0.0 - 1.0)**\n",
        "   - Controla el \"nucleus sampling\"\n",
        "   - 0.9 = considera tokens que suman 90% de probabilidad\n",
        "   - Alternativa a temperature (usar uno u otro)\n",
        "\n",
        "3. **üìè Max Output Tokens**\n",
        "   - Limita la longitud de la respuesta\n",
        "   - √ötil para controlar costos y concisi√≥n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "create-parametrized-agents"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üéõÔ∏è Agentes con diferentes par√°metros creados:\n",
            " ‚Ä¢ AgenteCreativo (temp=1.5)\n",
            " ‚Ä¢ AgenteTecnico (temp=0.1)\n",
            " ‚Ä¢ AgenteBalanceado (temp=0.7)\n",
            " ‚Ä¢ AgenteConciso (max_tokens=50)\n"
          ]
        }
      ],
      "source": [
        "# Agente Creativo (alta temperatura)\n",
        "agente_creativo = LlmAgent(\n",
        "    name=\"AgenteCreativo\",\n",
        "    model=azure_model,\n",
        "    description=\"Agente configurado para m√°xima creatividad\",\n",
        "    generate_content_config=types.GenerateContentConfig(\n",
        "        temperature= 1.5,          # Alta creatividad\n",
        "        max_output_tokens = 1000,    # Respuestas moderadas\n",
        "        top_k= 40                  # Vocabulario amplio\n",
        "     ),\n",
        "    instruction=(\n",
        "        \"Eres un escritor creativo e imaginativo.\"\n",
        "        \"Genera ideas originales y sorprendentes.\"\n",
        "        \"Usa met√°foras, analog√≠as y lenguaje colorido.\"\n",
        "    )\n",
        ")\n",
        "\n",
        "# Agente T√©cnico (baja temperatura)\n",
        "agente_tecnico = LlmAgent(\n",
        "    name=\"AgenteTecnico\",\n",
        "    model=azure_model,\n",
        "    description=\"Agente configurado para precisi√≥n t√©cnica\",\n",
        "    generate_content_config=types.GenerateContentConfig(\n",
        "        temperature= 0.1,          # Muy determinista\n",
        "        max_output_tokens= 150    # Respuestas concisas\n",
        "    ),\n",
        "    instruction=(\n",
        "        \"Eres un experto t√©cnico preciso y factual.\"\n",
        "        \"Proporciona informaci√≥n exacta y verificable.\"\n",
        "        \"Evita especulaciones y c√≠√±ete a los hechos.\"\n",
        "    )\n",
        ")\n",
        "\n",
        "# Agente Balanceado (configuraci√≥n media)\n",
        "agente_balanceado = LlmAgent(\n",
        "    name=\"AgenteBalanceado\",\n",
        "    model=azure_model,\n",
        "    description=\"Agente con configuraci√≥n equilibrada\",\n",
        "    generate_content_config=types.GenerateContentConfig(\n",
        "        temperature= 0.7,          # Balance\n",
        "        max_output_tokens= 300    # Flexibilidad en longitud\n",
        "    ),\n",
        "    instruction=(\n",
        "        \"Eres un asistente vers√°til y adaptable.\"\n",
        "        \"Proporciona respuestas √∫tiles y bien estructuradas.\"\n",
        "        \"Adapta tu estilo seg√∫n el contexto.\"\n",
        "    )\n",
        ")\n",
        "\n",
        "# Agente Ultra-Conciso (tokens limitados)\n",
        "agente_conciso = LlmAgent(\n",
        "    name=\"AgenteConciso\",\n",
        "    model=azure_model,\n",
        "    description=\"Agente de respuestas ultra-breves\",\n",
        "    generate_content_config=types.GenerateContentConfig(\n",
        "        temperature= 0.3,\n",
        "        max_output_tokens= 50     # Muy limitado\n",
        "    ),\n",
        "    instruction=(\n",
        "        \"Responde de forma extremadamente concisa.\"\n",
        "        \"M√°ximo 2-3 frases por respuesta.\"\n",
        "        \"Ve directo al punto, sin rodeos.\"\n",
        "    )\n",
        ")\n",
        "\n",
        "print(\"üéõÔ∏è Agentes con diferentes par√°metros creados:\")\n",
        "print(\" ‚Ä¢ AgenteCreativo (temp=1.5)\")\n",
        "print(\" ‚Ä¢ AgenteTecnico (temp=0.1)\")\n",
        "print(\" ‚Ä¢ AgenteBalanceado (temp=0.7)\")\n",
        "print(\" ‚Ä¢ AgenteConciso (max_tokens=50)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "parameters-demo"
      },
      "source": [
        "### üß™ Demostraci√≥n: Efecto de los Par√°metros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            ">>> Consulta del usuario: Escribe un poema sobre la luna llena\n",
            "<<< Respuesta del agente: **Bailarina de Plata**  \n",
            "\n",
            "Oh, luna llena, diadema del cielo,  \n",
            "caricia brillante en el manto negro,  \n",
            "bailarina et√©rea de luz y misterio,  \n",
            "te deslizas callada en un vasto silencio.  \n",
            "\n",
            "Eres el ojo abierto de la noche fr√≠a,  \n",
            "un espejo partido en la magia tard√≠a,  \n",
            "tu rostro se cuelga cual fruta prohibida,  \n",
            "mordida ya, solo por sue√±os y envidia.  \n",
            "\n",
            "Juegas con sombras, dibujas catedrales,  \n",
            "sobre las monta√±as, los r√≠os, los valles,  \n",
            "y entre los sauces, como augusta reina,  \n",
            "coronas el mundo con tu calma plena.  \n",
            "\n",
            "Beso de plata sobre el lomo del mar,  \n",
            "reflejo tembloroso que ans√≠a alcanzar  \n",
            "esa dama esquiva que vive en el cielo,  \n",
            "surcando las horas en un suave vuelo.  \n",
            "\n",
            "Los lobos a√∫llan tu nombre secreto,  \n",
            "y mil corazones laten un soneto.  \n",
            "Eres poema, eterna y desnuda,  \n",
            "musa brillante de la noche muda.  \n",
            "\n",
            "Oh luna llena, fanal de ensue√±o,  \n",
            "te inclinas paciente al nocturno due√±o.  \n",
            "Pero esta noche, serena y divina,  \n",
            "es tu reino eterno, oh dama argentina.  \n"
          ]
        }
      ],
      "source": [
        "APP_NAME = \"test_creative_agent\"\n",
        "USER_ID = \"user_6\"\n",
        "SESSION_ID = \"session_006\" # Using a fixed ID for simplicity\n",
        "\n",
        "session = await session_service.create_session(app_name=APP_NAME,user_id=USER_ID,session_id=SESSION_ID)\n",
        "runner_creativo = Runner(agent=agente_creativo,app_name=APP_NAME,session_service=session_service)\n",
        "\n",
        "await call_agent_async(\"Escribe un poema sobre la luna llena\",\n",
        "                        runner=runner_creativo,\n",
        "                        user_id=USER_ID,\n",
        "                        session_id=SESSION_ID)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            ">>> Consulta del usuario: Escribe un poema sobre la luna llena\n",
            "<<< Respuesta del agente: Luna redonda,  \n",
            "farol en la noche,  \n",
            "calma y asombro.\n"
          ]
        }
      ],
      "source": [
        "APP_NAME = \"test_conciso_agent\"\n",
        "USER_ID = \"user_6\"\n",
        "SESSION_ID = \"session_006\" # Using a fixed ID for simplicity\n",
        "\n",
        "\n",
        "session = await session_service.create_session(app_name=APP_NAME,user_id=USER_ID,session_id=SESSION_ID)\n",
        "runner_consiso = Runner(agent=agente_conciso,app_name=APP_NAME,session_service=session_service)\n",
        "\n",
        "await call_agent_async(\"Escribe un poema sobre la luna llena\",\n",
        "                        runner=runner_consiso,\n",
        "                        user_id=USER_ID,\n",
        "                        session_id=SESSION_ID)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "parameters-guide"
      },
      "source": [
        "### üìä Gu√≠a de Uso de Par√°metros\n",
        "\n",
        "Recomendaciones seg√∫n el caso de uso:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "parameters-guide-table"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä GU√çA DE PAR√ÅMETROS SEG√öN CASO DE USO\n",
            "\n",
            "          Caso de Uso Temperature Max Tokens    Top-p                      Raz√≥n\n",
            "Documentaci√≥n T√©cnica     0.1-0.3   500-1000 0.9-0.95   Precisi√≥n y consistencia\n",
            "   Escritura Creativa     0.8-1.5    200-500 0.95-1.0    Originalidad y variedad\n",
            "  Chatbot de Servicio     0.5-0.7    100-200      0.9       Balance y eficiencia\n",
            "    An√°lisis de Datos     0.1-0.2    300-500     0.95    Exactitud en resultados\n",
            "        Brainstorming     1.0-1.8    150-300 0.95-1.0 M√°xima diversidad de ideas\n",
            "\n",
            "\n",
            "‚ö†Ô∏è Notas importantes:\n",
            "   ‚Ä¢ Estos son rangos sugeridos, experimenta seg√∫n tus necesidades\n",
            "   ‚Ä¢ No uses temperature y top-p simult√°neamente en valores extremos\n",
            "   ‚Ä¢ El costo aumenta con max_tokens, √∫salo con prudencia\n",
            "   ‚Ä¢ Algunos modelos tienen l√≠mites espec√≠ficos, consulta la documentaci√≥n\n"
          ]
        }
      ],
      "source": [
        "# Crear una gu√≠a visual de par√°metros\n",
        "import pandas as pd\n",
        "\n",
        "# Crear tabla de recomendaciones\n",
        "guia_parametros = pd.DataFrame([\n",
        "    {\"Caso de Uso\": \"Documentaci√≥n T√©cnica\", \n",
        "     \"Temperature\": \"0.1-0.3\", \n",
        "     \"Max Tokens\": \"500-1000\", \n",
        "     \"Top-p\": \"0.9-0.95\",\n",
        "     \"Raz√≥n\": \"Precisi√≥n y consistencia\"},\n",
        "    \n",
        "    {\"Caso de Uso\": \"Escritura Creativa\", \n",
        "     \"Temperature\": \"0.8-1.5\", \n",
        "     \"Max Tokens\": \"200-500\", \n",
        "     \"Top-p\": \"0.95-1.0\",\n",
        "     \"Raz√≥n\": \"Originalidad y variedad\"},\n",
        "    \n",
        "    {\"Caso de Uso\": \"Chatbot de Servicio\", \n",
        "     \"Temperature\": \"0.5-0.7\", \n",
        "     \"Max Tokens\": \"100-200\", \n",
        "     \"Top-p\": \"0.9\",\n",
        "     \"Raz√≥n\": \"Balance y eficiencia\"},\n",
        "    \n",
        "    {\"Caso de Uso\": \"An√°lisis de Datos\", \n",
        "     \"Temperature\": \"0.1-0.2\", \n",
        "     \"Max Tokens\": \"300-500\", \n",
        "     \"Top-p\": \"0.95\",\n",
        "     \"Raz√≥n\": \"Exactitud en resultados\"},\n",
        "    \n",
        "    {\"Caso de Uso\": \"Brainstorming\", \n",
        "     \"Temperature\": \"1.0-1.8\", \n",
        "     \"Max Tokens\": \"150-300\", \n",
        "     \"Top-p\": \"0.95-1.0\",\n",
        "     \"Raz√≥n\": \"M√°xima diversidad de ideas\"}\n",
        "])\n",
        "\n",
        "print(\"üìä GU√çA DE PAR√ÅMETROS SEG√öN CASO DE USO\\n\")\n",
        "print(guia_parametros.to_string(index=False))\n",
        "\n",
        "print(\"\\n\\n‚ö†Ô∏è Notas importantes:\")\n",
        "print(\"   ‚Ä¢ Estos son rangos sugeridos, experimenta seg√∫n tus necesidades\")\n",
        "print(\"   ‚Ä¢ No uses temperature y top-p simult√°neamente en valores extremos\")\n",
        "print(\"   ‚Ä¢ El costo aumenta con max_tokens, √∫salo con prudencia\")\n",
        "print(\"   ‚Ä¢ Algunos modelos tienen l√≠mites espec√≠ficos, consulta la documentaci√≥n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "structured-output-intro"
      },
      "source": [
        "## üìä Parte 3: Output Estructurado con Pydantic\n",
        "\n",
        "### ¬øPor qu√© Output Estructurado?\n",
        "\n",
        "El output estructurado es crucial cuando necesitas:\n",
        "- üîß Integrar respuestas de IA con otros sistemas\n",
        "- üíæ Almacenar datos en bases de datos\n",
        "- üéØ Garantizar formato consistente\n",
        "- ‚úÖ Validar la informaci√≥n extra√≠da\n",
        "\n",
        "### Pydantic: La Soluci√≥n\n",
        "\n",
        "Pydantic permite definir esquemas de datos con:\n",
        "- Type hints de Python\n",
        "- Validaci√≥n autom√°tica\n",
        "- Serializaci√≥n JSON\n",
        "- Documentaci√≥n clara para el LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "create-pydantic-models"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìö Creando modelos Pydantic para output estructurado...\n",
            "\n",
            "‚úÖ Modelos Pydantic creados:\n",
            "   1. InformacionProducto - Para extraer datos de productos\n",
            "   2. AnalisisSentimiento - Para an√°lisis de opiniones\n",
            "   3. Evento/ListaEventos - Para extraer informaci√≥n de eventos\n",
            "\n",
            "üìã Ejemplo de esquema (InformacionProducto):\n",
            "{'nombre': {'description': 'Nombre completo del producto', 'title': 'Nombre', 'type': 'string'}, 'marca': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'default': None, 'description': 'Marca del producto', 'title': 'Marca'}, 'precio': {'anyOf': [{'type': 'number'}, {'type': 'null'}], 'default': None, 'description': 'Precio en USD', 'title': 'Precio'}, 'caracteristicas': {'description': 'Lista de caracter√≠sticas principales', 'items': {'type': 'string'}, 'title': 'Caracteristicas', 'type': 'array'}, 'disponible': {'default': True, 'description': 'Si est√° disponible', 'title': 'Disponible', 'type': 'boolean'}, 'categoria': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'default': None, 'description': 'Categor√≠a del producto', 'title': 'Categoria'}}\n"
          ]
        }
      ],
      "source": [
        "# Importar Pydantic y crear modelos de datos\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import List, Optional\n",
        "\n",
        "print(\"üìö Creando modelos Pydantic para output estructurado...\\n\")\n",
        "\n",
        "# Modelo 1: Informaci√≥n de Producto\n",
        "class InformacionProducto(BaseModel):\n",
        "    \"\"\"Esquema para extraer informaci√≥n de productos\"\"\"\n",
        "    nombre: str = Field(description=\"Nombre completo del producto\")\n",
        "    marca: Optional[str] = Field(None, description=\"Marca del producto\")\n",
        "    precio: Optional[float] = Field(None, description=\"Precio en USD\")\n",
        "    caracteristicas: List[str] = Field(\n",
        "        default_factory=list,\n",
        "        description=\"Lista de caracter√≠sticas principales\"\n",
        "    )\n",
        "    disponible: bool = Field(True, description=\"Si est√° disponible\")\n",
        "    categoria: Optional[str] = Field(None, description=\"Categor√≠a del producto\")\n",
        "\n",
        "# Modelo 2: An√°lisis de Sentimiento\n",
        "class AnalisisSentimiento(BaseModel):\n",
        "    \"\"\"Esquema para an√°lisis de sentimiento de texto\"\"\"\n",
        "    sentimiento: str = Field(\n",
        "        description=\"Sentimiento general: positivo, negativo o neutral\"\n",
        "    )\n",
        "    confianza: float = Field(\n",
        "        description=\"Nivel de confianza del an√°lisis (0.0 a 1.0)\",\n",
        "        ge=0.0, le=1.0\n",
        "    )\n",
        "    emociones: List[str] = Field(\n",
        "        default_factory=list,\n",
        "        description=\"Emociones detectadas en el texto\"\n",
        "    )\n",
        "    aspectos_positivos: List[str] = Field(\n",
        "        default_factory=list,\n",
        "        description=\"Aspectos positivos mencionados\"\n",
        "    )\n",
        "    aspectos_negativos: List[str] = Field(\n",
        "        default_factory=list,\n",
        "        description=\"Aspectos negativos mencionados\"\n",
        "    )\n",
        "\n",
        "# Modelo 3: Extracci√≥n de Eventos\n",
        "class Evento(BaseModel):\n",
        "    \"\"\"Informaci√≥n sobre un evento\"\"\"\n",
        "    titulo: str = Field(description=\"T√≠tulo del evento\")\n",
        "    fecha: Optional[str] = Field(None, description=\"Fecha del evento (YYYY-MM-DD)\")\n",
        "    hora: Optional[str] = Field(None, description=\"Hora del evento (HH:MM)\")\n",
        "    ubicacion: Optional[str] = Field(None, description=\"Ubicaci√≥n del evento\")\n",
        "    participantes: List[str] = Field(\n",
        "        default_factory=list,\n",
        "        description=\"Lista de participantes\"\n",
        "    )\n",
        "    descripcion: Optional[str] = Field(None, description=\"Descripci√≥n del evento\")\n",
        "\n",
        "class ListaEventos(BaseModel):\n",
        "    \"\"\"Lista de eventos extra√≠dos\"\"\"\n",
        "    eventos: List[Evento] = Field(\n",
        "        default_factory=list,\n",
        "        description=\"Lista de todos los eventos encontrados\"\n",
        "    )\n",
        "    total_eventos: int = Field(\n",
        "        description=\"N√∫mero total de eventos encontrados\"\n",
        "    )\n",
        "\n",
        "print(\"‚úÖ Modelos Pydantic creados:\")\n",
        "print(\"   1. InformacionProducto - Para extraer datos de productos\")\n",
        "print(\"   2. AnalisisSentimiento - Para an√°lisis de opiniones\")\n",
        "print(\"   3. Evento/ListaEventos - Para extraer informaci√≥n de eventos\")\n",
        "\n",
        "# Ejemplo de uso\n",
        "print(\"\\nüìã Ejemplo de esquema (InformacionProducto):\")\n",
        "print(InformacionProducto.model_json_schema()['properties'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creando los agentes con structured Output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "create-structured-agents"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Invalid config for agent ExtractorProductos: output_schema cannot co-exist with agent transfer configurations. Setting disallow_transfer_to_parent=True, disallow_transfer_to_peers=True\n",
            "Invalid config for agent AnalizadorSentimientos: output_schema cannot co-exist with agent transfer configurations. Setting disallow_transfer_to_parent=True, disallow_transfer_to_peers=True\n",
            "Invalid config for agent ExtractorEventos: output_schema cannot co-exist with agent transfer configurations. Setting disallow_transfer_to_parent=True, disallow_transfer_to_peers=True\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üéØ Agentes con output estructurado creados:\n",
            "   ‚Ä¢ ExtractorProductos ‚Üí InformacionProducto\n",
            "   ‚Ä¢ AnalizadorSentimientos ‚Üí AnalisisSentimiento\n",
            "   ‚Ä¢ ExtractorEventos ‚Üí ListaEventos\n"
          ]
        }
      ],
      "source": [
        "# Crear agentes con output estructurado\n",
        "\n",
        "# Agente Extractor de Productos\n",
        "agente_extractor_productos = LlmAgent(\n",
        "    name=\"ExtractorProductos\",\n",
        "    model=\"gemini-2.5-flash\",  # Pro maneja mejor output estructurado\n",
        "    description=\"Extrae informaci√≥n estructurada de productos\",\n",
        "    output_schema=InformacionProducto,  # ¬°Output estructurado!\n",
        "    output_key='InformacionProducto',  # Clave para el output\n",
        "    generate_content_config=types.GenerateContentConfig(\n",
        "        temperature= 0.1,\n",
        "        max_output_tokens= 300\n",
        "    ),\n",
        "    instruction=(\n",
        "        \"Extrae informaci√≥n de productos del texto proporcionado.\"\n",
        "        \"Sigue exactamente el esquema definido.\"\n",
        "        \"Si no encuentras alg√∫n dato, usa None o lista vac√≠a seg√∫n corresponda.\"\n",
        "        \"S√© preciso con los precios y caracter√≠sticas.\"\n",
        "    )\n",
        ")\n",
        "\n",
        "# Agente Analizador de Sentimientos\n",
        "agente_sentimientos = LlmAgent(\n",
        "    name=\"AnalizadorSentimientos\",\n",
        "    model=openai_model,\n",
        "    description=\"Analiza el sentimiento y emociones en textos\",\n",
        "    output_schema=AnalisisSentimiento,  # ¬°Output estructurado!\n",
        "    output_key='AnalisisSentimiento',  # Clave para el output\n",
        "    generate_content_config=types.GenerateContentConfig(\n",
        "        temperature= 0.3,\n",
        "        max_output_tokens= 300\n",
        "    ),\n",
        "    instruction=(\n",
        "        \"Analiza el sentimiento del texto proporcionado.\"\n",
        "        \"Identifica emociones espec√≠ficas presentes.\"\n",
        "        \"Lista aspectos positivos y negativos mencionados.\"\n",
        "        \"Asigna un nivel de confianza a tu an√°lisis (0.0 a 1.0).\"\n",
        "    )\n",
        ")\n",
        "\n",
        "# Agente Extractor de Eventos\n",
        "agente_eventos = LlmAgent(\n",
        "    name=\"ExtractorEventos\",\n",
        "    model=anthropic_model,\n",
        "    description=\"Extrae informaci√≥n de eventos de un texto\",\n",
        "    output_schema=ListaEventos,  # ¬°Output estructurado con lista!\n",
        "    output_key='ListaEventos',  # Clave para el output\n",
        "    generate_content_config=types.GenerateContentConfig(\n",
        "        temperature= 0.2,\n",
        "        max_output_tokens= 500\n",
        "    ),\n",
        "    instruction=(\n",
        "        \"Extrae TODOS los eventos mencionados en el texto.\"\n",
        "        \"Para cada evento, captura toda la informaci√≥n disponible.\"\n",
        "        \"Las fechas deben estar en formato YYYY-MM-DD.\"\n",
        "        \"Las horas en formato HH:MM.\"\n",
        "        \"Si hay m√∫ltiples eventos, incl√∫yelos todos en la lista.\"\n",
        "    )\n",
        ")\n",
        "\n",
        "print(\"üéØ Agentes con output estructurado creados:\")\n",
        "print(\"   ‚Ä¢ ExtractorProductos ‚Üí InformacionProducto\")\n",
        "print(\"   ‚Ä¢ AnalizadorSentimientos ‚Üí AnalisisSentimiento\")\n",
        "print(\"   ‚Ä¢ ExtractorEventos ‚Üí ListaEventos\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Probando el primer agente de productos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            ">>> Consulta del usuario: \n",
            "    El nuevo iPhone 15 Pro Max de Apple ya est√° disponible. \n",
            "    Con un precio de $1,199, incluye c√°mara de 48MP, pantalla de 6.7 pulgadas,\n",
            "    chip A17 Pro y bater√≠a de larga duraci√≥n. Disponible en titanio.\n",
            "    \n",
            "<<< Respuesta del agente: {\n",
            "  \"nombre\": \"iPhone 15 Pro Max\",\n",
            "  \"marca\": \"Apple\",\n",
            "  \"precio\": 1199,\n",
            "  \"caracteristicas\": [\n",
            "    \"c√°mara de 48MP\",\n",
            "    \"pantalla de 6.7 pulgadas\",\n",
            "    \"chip A17 Pro\",\n",
            "    \"bater√≠a de larga duraci√≥n\",\n",
            "    \"Disponible en titanio\"\n",
            "  ],\n",
            "  \"disponible\": true,\n",
            "  \"categoria\": null\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "APP_NAME = \"output_1\"\n",
        "USER_ID = \"user_7\"\n",
        "SESSION_ID = \"session_007\" # Using a fixed ID for simplicity\n",
        "\n",
        "texto_producto = \"\"\"\n",
        "    El nuevo iPhone 15 Pro Max de Apple ya est√° disponible. \n",
        "    Con un precio de $1,199, incluye c√°mara de 48MP, pantalla de 6.7 pulgadas,\n",
        "    chip A17 Pro y bater√≠a de larga duraci√≥n. Disponible en titanio.\n",
        "    \"\"\"\n",
        "\n",
        "session = await session_service.create_session(app_name=APP_NAME,user_id=USER_ID,session_id=SESSION_ID)\n",
        "runner_productos = Runner(agent=agente_extractor_productos,app_name=APP_NAME,session_service=session_service)\n",
        "\n",
        "await call_agent_async(texto_producto,\n",
        "                        runner=runner_productos,\n",
        "                        user_id=USER_ID,\n",
        "                        session_id=SESSION_ID)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Probando el segundo agente de sentimientos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            ">>> Consulta del usuario: \n",
            "    El nuevo iPhone 15 Pro Max de Apple ya est√° disponible. \n",
            "    Con un precio de $1,199, incluye c√°mara de 48MP, pantalla de 6.7 pulgadas,\n",
            "    chip A17 Pro y bater√≠a de larga duraci√≥n. Disponible en titanio.\n",
            "    \n",
            "<<< Respuesta del agente: {\"sentimiento\":\"neutral\",\"confianza\":0.9,\"emociones\":[],\"aspectos_positivos\":[\"c√°mara de 48MP\",\"pantalla de 6.7 pulgadas\",\"chip A17 Pro\",\"bater√≠a de larga duraci√≥n\",\"disponible en titanio\"],\"aspectos_negativos\":[\"precio de $1,199\"]}\n"
          ]
        }
      ],
      "source": [
        "APP_NAME = \"output_2\"\n",
        "USER_ID = \"user_7\"\n",
        "SESSION_ID = \"session_007\" # Using a fixed ID for simplicity\n",
        "\n",
        "texto_opinion = \"\"\"\n",
        "    ¬°Me encanta mi nuevo laptop! La velocidad es incre√≠ble y la pantalla es hermosa.\n",
        "    Sin embargo, la bater√≠a no dura tanto como esperaba y el precio fue algo alto.\n",
        "    En general, estoy satisfecho con la compra.\n",
        "    \"\"\"\n",
        "\n",
        "session = await session_service.create_session(app_name=APP_NAME,user_id=USER_ID,session_id=SESSION_ID)\n",
        "runner_sentimientos = Runner(agent=agente_sentimientos,app_name=APP_NAME,session_service=session_service)\n",
        "\n",
        "await call_agent_async(texto_producto,\n",
        "                        runner=runner_sentimientos,\n",
        "                        user_id=USER_ID,\n",
        "                        session_id=SESSION_ID)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Probando el tercer agente de eventos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            ">>> Consulta del usuario: \n",
            "    Recordatorio: La conferencia de IA ser√° el 15 de marzo de 2024 a las 10:00 AM\n",
            "    en el Centro de Convenciones. Participar√°n el Dr. Smith y la Dra. Johnson.\n",
            "    Despu√©s, habr√° un taller pr√°ctico a las 2:00 PM en el mismo lugar.\n",
            "    \n",
            "<<< Respuesta del agente: {\"eventos\": [{\"titulo\": \"Conferencia de IA\", \"fecha\": \"2024-03-15\", \"hora\": \"10:00\", \"ubicacion\": \"Centro de Convenciones\", \"participantes\": [\"Dr. Smith\", \"Dra. Johnson\"], \"descripcion\": null}, {\"titulo\": \"Taller pr\\u00e1ctico\", \"fecha\": \"2024-03-15\", \"hora\": \"14:00\", \"ubicacion\": \"Centro de Convenciones\", \"participantes\": [], \"descripcion\": null}], \"total_eventos\": 2}\n"
          ]
        }
      ],
      "source": [
        "APP_NAME = \"output_3\"\n",
        "USER_ID = \"user_7\"\n",
        "SESSION_ID = \"session_007\" # Using a fixed ID for simplicity\n",
        "\n",
        "texto_eventos = \"\"\"\n",
        "    Recordatorio: La conferencia de IA ser√° el 15 de marzo de 2024 a las 10:00 AM\n",
        "    en el Centro de Convenciones. Participar√°n el Dr. Smith y la Dra. Johnson.\n",
        "    Despu√©s, habr√° un taller pr√°ctico a las 2:00 PM en el mismo lugar.\n",
        "    \"\"\"\n",
        "\n",
        "session = await session_service.create_session(app_name=APP_NAME,user_id=USER_ID,session_id=SESSION_ID)\n",
        "runner_eventos = Runner(agent=agente_eventos,app_name=APP_NAME,session_service=session_service)\n",
        "\n",
        "await call_agent_async(texto_eventos,\n",
        "                        runner=runner_eventos,\n",
        "                        user_id=USER_ID,\n",
        "                        session_id=SESSION_ID)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "____"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéì RESUMEN DEL TUTORIAL 2: CONTROL DE LLMs\n",
        "---\n",
        "\n",
        "### 1Ô∏è‚É£ LiteLLM - Flexibilidad de Modelos\n",
        "- ‚úÖ Usa cualquier modelo con el prefijo `litellm/`\n",
        "- ‚úÖ Soporte para **100+ modelos diferentes**\n",
        "- ‚úÖ Cambio f√°cil entre proveedores\n",
        "- ‚úÖ Optimizaci√≥n de **costos y rendimiento**\n",
        "\n",
        "---\n",
        "\n",
        "### 2Ô∏è‚É£ Par√°metros de LLM - Control\n",
        "- ‚úÖ `temperature`: controla la **creatividad vs consistencia**\n",
        "- ‚úÖ `max_tokens`: limita la **longitud** de la respuesta y ayuda a controlar costos\n",
        "- ‚úÖ `top_p`: alternativa a `temperature` para muestreo\n",
        "- ‚úÖ Configuraci√≥n ajustada seg√∫n el **caso de uso**\n",
        "\n",
        "---\n",
        "\n",
        "### 3Ô∏è‚É£ Output Estructurado - Respuestas Predecibles\n",
        "- ‚úÖ Uso de **Pydantic** para definir esquemas de respuesta\n",
        "- ‚úÖ **Validaci√≥n autom√°tica** de los datos generados por el modelo\n",
        "- ‚úÖ Integraci√≥n sencilla con otros sistemas\n",
        "- ‚úÖ Producci√≥n de **JSON consistente y tipado**\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "farewell"
      },
      "source": [
        "---\n",
        "\n",
        "## üéâ ¬°Felicitaciones!\n",
        "\n",
        "Has completado el Tutorial 2 de Google ADK. Ahora tienes el poder de:\n",
        "- Integrar cualquier LLM en tus agentes\n",
        "- Controlar finamente su comportamiento\n",
        "- Obtener respuestas estructuradas y validadas\n",
        "\n",
        "**Siguiente paso**: Tutorial 3 - Herramientas  üõ†Ô∏è\n",
        "\n",
        "---\n",
        "\n",
        "**¬øPreguntas?** D√©jalas en los comentarios del video o consulta la documentaci√≥n oficial.\n",
        "\n",
        "**¬°Feliz codificaci√≥n con ADK!** üöÄ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "resources"
      },
      "source": [
        "## üìö Recursos Adicionales\n",
        "\n",
        "### Enlaces √ötiles\n",
        "\n",
        "- **Documentaci√≥n ADK**: [https://google.github.io/adk-docs/](https://google.github.io/adk-docs/)\n",
        "- **LiteLLM Docs**: [https://docs.litellm.ai/](https://docs.litellm.ai/)\n",
        "- **Pydantic Docs**: [https://docs.pydantic.dev/](https://docs.pydantic.dev/)\n",
        "- **Modelos Soportados**: [Lista completa de LiteLLM](https://docs.litellm.ai/docs/providers)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "workspace",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
