{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vertexai\n",
    "from vertexai.preview import reasoning_engines\n",
    "\n",
    "\n",
    "PROJECT_ID = \"gde-access\"\n",
    "LOCATION = \"us-central1\"\n",
    "STAGING_BUCKET = \"gs://alarcon_agent_bucket\"\n",
    "\n",
    "vertexai.init(\n",
    "    project=PROJECT_ID,\n",
    "    location=LOCATION,\n",
    "    staging_bucket=STAGING_BUCKET,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delete Agent Engine backing LRO: projects/744349094145/locations/us-central1/operations/4420117025188216832\n",
      "Agent Engine deleted. Resource name: projects/gde-access/locations/us-central1/reasoningEngines/8979746648418680832\n"
     ]
    }
   ],
   "source": [
    "agent_engine = vertexai.agent_engines.get('projects/gde-access/locations/us-central1/reasoningEngines/8979746648418680832')\n",
    "agent_engine.delete(force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alarcon7a/anaconda3/envs/env_3_10/lib/python3.10/site-packages/pydantic/_internal/_fields.py:198: UserWarning: Field name \"config_type\" in \"SequentialAgent\" shadows an attribute in parent \"BaseAgent\"\n",
      "  warnings.warn(\n",
      "/home/alarcon7a/anaconda3/envs/env_3_10/lib/python3.10/site-packages/google/auth/_default.py:76: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. See the following page for troubleshooting: https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds. \n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "from vertexai import agent_engines\n",
    "\n",
    "agent = agent_engines.get(\"8979746648418680832\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.operation_schemas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "from fastapi import FastAPI, Request\n",
    "from google import auth as google_auth\n",
    "from google.auth.transport import requests as google_requests\n",
    "\n",
    "# ========= ENV REQUERIDAS =========\n",
    "#  - D360_API_KEY: tu API key de 360dialog (D360-API-KEY)\n",
    "#  - GCP_PROJECT:    ID de tu proyecto GCP\n",
    "#  - GCP_LOCATION:   region (p.ej. \"us-central1\")\n",
    "#  - REASONING_ENGINE_ID: ID del Reasoning Engine (solo el id numérico o nombre)\n",
    "#  - WHATSAPP_VERIFY_TOKEN: token que tú inventas para verificación del webhook (opcional pero recomendado)\n",
    "#\n",
    "# Autenticación GCP (elige una):\n",
    "#  A) ADC local: ejecuta `gcloud auth application-default login`\n",
    "#  B) SERVICE ACCOUNT: exporta GOOGLE_APPLICATION_CREDENTIALS=/ruta/sa.json\n",
    "\n",
    "D360_API_KEY = 'khSBsCpyk1Ex4xDO6bMvwAnSAK'\n",
    "GCP_PROJECT = \"gde-access\"\n",
    "GCP_LOCATION = \"us-central1\"\n",
    "REASONING_ENGINE_ID = 'projects/744349094145/locations/us-central1/reasoningEngines/2151726663371587584'\n",
    "WHATSAPP_VERIFY_TOKEN = os.getenv(\"WHATSAPP_VERIFY_TOKEN\", \"cambia_esto\")\n",
    "\n",
    "assert D360_API_KEY, \"Falta D360_API_KEY\"\n",
    "assert GCP_PROJECT, \"Falta GCP_PROJECT\"\n",
    "assert REASONING_ENGINE_ID, \"Falta REASONING_ENGINE_ID\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, Generator, Optional, Union\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gcp_access_token() -> str:\n",
    "    \"\"\"Obtiene access_token con Application Default Credentials (ADC).\"\"\"\n",
    "    credentials, _ = google_auth.default()\n",
    "    req = google_requests.Request()\n",
    "    credentials.refresh(req)\n",
    "    return credentials.token\n",
    "\n",
    "def agent_query(user_text: str) -> str:\n",
    "    \"\"\"Llama al Agent Engine de Vertex AI (modo síncrono :query).\"\"\"\n",
    "    url = (f\"https://{GCP_LOCATION}-aiplatform.googleapis.com/v1/{REASONING_ENGINE_ID}:query\")\n",
    "    payload = {\n",
    "        \"class_method\": \"stream_query\",\n",
    "        \"input\": {\"message\": user_text,\n",
    "                  \"user_id\": \"u_456\",}\n",
    "    }\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {gcp_access_token()}\",\n",
    "        \"Content-Type\": \"application/json; charset=utf-8\"\n",
    "    }\n",
    "    r = requests.post(url, headers=headers, data=json.dumps(payload), timeout=60)\n",
    "    r.raise_for_status()\n",
    "    data = r.json()\n",
    "    return data.get(\"output\") or str(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_stream_query(\n",
    "    message: Union[str, Dict[str, Any]],\n",
    "    user_id: str,\n",
    "    session_id: Optional[str] = None,\n",
    "    **kwargs: Dict[str, Any],\n",
    ") -> Generator[Dict[str, Any], None, None]:\n",
    "    \"\"\"\n",
    "    Llama al endpoint :streamQuery (SSE) del Agent Engine y va rindiendo eventos.\n",
    "    Respeta el esquema:\n",
    "      - required: message, user_id\n",
    "      - optional: session_id\n",
    "      - **kwargs: se envían en el payload para el runner\n",
    "    Yields: dict con el contenido de cada \"data:\" del SSE (parseado como JSON).\n",
    "    \"\"\"\n",
    "    assert GCP_PROJECT and REASONING_ENGINE_ID, \"Falta configurar GCP_PROJECT/REASONING_ENGINE_ID\"\n",
    "\n",
    "    url = (f\"https://{GCP_LOCATION}-aiplatform.googleapis.com/v1/projects/{GCP_PROJECT}\"\n",
    "           f\"/locations/{GCP_LOCATION}/reasoningEngines/{REASONING_ENGINE_ID}:streamQuery\")\n",
    "\n",
    "    payload: Dict[str, Any] = {\n",
    "        \"message\": message,\n",
    "        \"user_id\": user_id,\n",
    "    }\n",
    "    if session_id is not None:\n",
    "        payload[\"session_id\"] = session_id\n",
    "    if kwargs:\n",
    "        payload.update(kwargs)\n",
    "\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {gcp_access_token()}\",\n",
    "        \"Content-Type\": \"application/json; charset=utf-8\",\n",
    "        \"Accept\": \"text/event-stream\",\n",
    "    }\n",
    "\n",
    "    with requests.post(url, headers=headers, data=json.dumps(payload), stream=True, timeout=300) as r:\n",
    "        r.raise_for_status()\n",
    "        for raw in r.iter_lines(decode_unicode=True):\n",
    "            if not raw:\n",
    "                continue\n",
    "            # Formato SSE típico: \"data: {...json...}\"\n",
    "            if raw.startswith(\"data:\"):\n",
    "                try:\n",
    "                    evt = json.loads(raw[len(\"data:\"):].strip())\n",
    "                except Exception:\n",
    "                    # Algunos proveedores mandan \"data: [DONE]\" u otros marcadores\n",
    "                    if raw.strip().endswith(\"[DONE]\"):\n",
    "                        break\n",
    "                    continue\n",
    "                yield evt\n",
    "\n",
    "def collect_stream_to_text(\n",
    "    message: Union[str, Dict[str, Any]],\n",
    "    user_id: str,\n",
    "    session_id: Optional[str] = None,\n",
    "    **kwargs: Dict[str, Any],\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Consume agent_stream_query y devuelve un solo string.\n",
    "    Intenta extraer delta/choices/output según lo que emita el runner.\n",
    "    \"\"\"\n",
    "    parts: list[str] = []\n",
    "    for evt in agent_stream_query(message=message, user_id=user_id, session_id=session_id, **kwargs):\n",
    "        # Heurísticas comunes de eventos:\n",
    "        # - evt.get(\"delta\")           -> fragmento parcial\n",
    "        # - evt.get(\"output\")          -> bloque final o parcial\n",
    "        # - evt.get(\"text\") / \"token\"  -> algunos runners emiten así\n",
    "        for key in (\"delta\", \"output\", \"text\", \"token\"):\n",
    "            val = evt.get(key)\n",
    "            if isinstance(val, str):\n",
    "                parts.append(val)\n",
    "    return \"\".join(parts).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcp_access_token()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import auth as google_auth\n",
    "from google.auth.transport import requests as google_requests\n",
    "import requests\n",
    "import json\n",
    "\n",
    "def get_identity_token():\n",
    "    credentials, _ = google_auth.default()\n",
    "    auth_request = google_requests.Request()\n",
    "    credentials.refresh(auth_request)\n",
    "    return credentials.token\n",
    "\n",
    "# Hacer request con streaming\n",
    "response = requests.post(\n",
    "    f\"https://us-central1-aiplatform.googleapis.com/v1/projects/744349094145/locations/us-central1/reasoningEngines/2151726663371587584:streamQuery\",\n",
    "    headers={\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {get_identity_token()}\",\n",
    "    },\n",
    "    data=json.dumps({\n",
    "        \"class_method\": \"stream_query\",\n",
    "        \"input\": {\n",
    "            \"message\": \"Cual es la hora en newyork?\",\n",
    "            \"user_id\": \"user_1234\",  # Requerido\n",
    "        }\n",
    "    }),\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "# Procesar respuestas en streaming\n",
    "for line in response.iter_lines():\n",
    "    if line:\n",
    "        print(line.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_query_stream(user_text: str, user_id: str, session_id: str = None) -> str:\n",
    "    \"\"\"Llama al Agent Engine de Vertex AI (modo streaming: stream_query).\"\"\"\n",
    "    url = f\"https://us-central1-aiplatform.googleapis.com/v1/projects/744349094145/locations/us-central1/reasoningEngines/2151726663371587584:streamQuery\"\n",
    "    payload = {\n",
    "        \"class_method\": \"stream_query\",\n",
    "        \"input\": {\n",
    "            \"message\": user_text,\n",
    "            \"user_id\": user_id,\n",
    "            \"session_id\": session_id  # Opcional, se crea automáticamente si es None\n",
    "        }\n",
    "    }\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {get_identity_token()}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    response = requests.post(url, headers=headers, data=json.dumps(payload), stream=True, timeout=60)\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    # Recopilar todas las respuestas del stream\n",
    "    full_response = \"\"\n",
    "    final_output = None\n",
    "    \n",
    "    # Procesar cada línea del stream\n",
    "    for line in response.iter_lines():\n",
    "        if line:\n",
    "            try:\n",
    "                line_str = line.decode('utf-8').strip()\n",
    "                if line_str:  # Si la línea no está vacía\n",
    "                    data = json.loads(line_str)\n",
    "                    \n",
    "                    # Buscar respuesta final en content.parts\n",
    "                    if 'content' in data and 'parts' in data['content']:\n",
    "                        for part in data['content']['parts']:\n",
    "                            # Si es una respuesta de texto (respuesta final)\n",
    "                            if 'text' in part and data['content'].get('role') == 'model':\n",
    "                                final_response = part['text']\n",
    "                            \n",
    "            except (json.JSONDecodeError, UnicodeDecodeError, KeyError):\n",
    "                continue\n",
    "    \n",
    "    return final_response or \"No se recibió respuesta válida\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_query_stream(\"whats the weather in new york\", user_id=\"u_456\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_3_10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
