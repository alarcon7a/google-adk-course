{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü§ñ ADK: Create Agent Teams! Orchestration and Workflows (Class 5)\n",
    "\n",
    "## üìö Introduction\n",
    "\n",
    "In this class you will learn to:\n",
    "- Coordinate multiple agents to execute complex tasks\n",
    "- Use workflow agents (SequentialAgent, ParallelAgent, LoopAgent)\n",
    "- Implement dynamic routing with manager agents\n",
    "- Build a complete multi-agent system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Installation and Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADK Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Google ADK\n",
    "!pip install -q google-adk==1.4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import logging\n",
    "from typing_extensions import override\n",
    "\n",
    "# ADK imports\n",
    "from google.adk.agents import (\n",
    "    LlmAgent, \n",
    "    SequentialAgent, \n",
    "    ParallelAgent, \n",
    "    LoopAgent\n",
    "    )\n",
    "from google.adk.runners import Runner\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.genai import types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 1: Enter them directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "# Request API Key securely\n",
    "if 'GOOGLE_API_KEY' not in os.environ:\n",
    "    print(\"üîë Please enter your Google API Key:\")\n",
    "    api_key = getpass(\"API Key: \")\n",
    "    os.environ['GOOGLE_API_KEY'] = api_key\n",
    "    os.environ['GOOGLE_GENAI_USE_VERTEXAI'] = 'FALSE'\n",
    "    print(\"\\n‚úÖ API Key configured correctly\")\n",
    "else:\n",
    "    print(\"‚úÖ API Key already configured\")\n",
    "\n",
    "# Verify that variables are configured\n",
    "print(f\"\\nüìã Configured environment variables:\")\n",
    "print(f\"   - GOOGLE_API_KEY: {'‚úì' if os.environ.get('GOOGLE_API_KEY') else '‚úó'}\")\n",
    "print(f\"   - GOOGLE_GENAI_USE_VERTEXAI: {os.environ.get('GOOGLE_GENAI_USE_VERTEXAI', 'Not configured')}\")\n",
    "\n",
    "print(\"‚úÖ ADK installed and configured correctly!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 2: Load via Dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "# Load environment variables from .env if it exists\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our inference function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def call_agent_async_with_full_trace(query: str, runner, user_id, session_id):\n",
    "    \"\"\"Sends a query to the agent and prints the final response and trace of each step.\"\"\"\n",
    "    print(f\"\\n>>> User query: {query}\")\n",
    "    print(\"--- Starting data processing pipeline ---\")\n",
    "\n",
    "    content = types.Content(role='user', parts=[types.Part(text=query)])\n",
    "    final_response_text = \"The agent did not produce a final response.\"\n",
    "\n",
    "    # Iterate through *all* pipeline events to see the complete trace.\n",
    "    # Do NOT use 'break' inside this loop.\n",
    "    async for event in runner.run_async(user_id=user_id, session_id=session_id, new_message=content):\n",
    "        # Print each event that has text content to see the trace.\n",
    "        if event.content and event.content.parts and event.content.parts[0].text:\n",
    "            # Include the 'Author' (agent name) and event 'Type' for clarity.\n",
    "            print(f\"----->>> [Event] Author: {event.author}, Type: {type(event).__name__}, Content: '{event.content.parts[0].text}'\")\n",
    "\n",
    "        # Capture the final response when the SequentialAgent finishes.\n",
    "        # This logic executes on each event, ensuring the last response is saved.\n",
    "        if event.is_final_response():\n",
    "            if event.content and event.content.parts:\n",
    "                final_response_text = event.content.parts[0].text\n",
    "\n",
    "    print(\"--- Finishing data processing pipeline ---\")\n",
    "    print(f\"\\n<<< Final agent response: {final_response_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Part 1: What is Agent Orchestration?\n",
    "\n",
    "Agent orchestration is the art of **coordinating multiple specialized agents** to achieve complex objectives. Instead of a monolithic agent, we divide the problem into manageable subtasks.\n",
    "\n",
    "### Advantages of Orchestration:\n",
    "- **Modularity**: Simpler agents that are easier to maintain\n",
    "- **Reusability**: Specialists can be used in different flows\n",
    "- **Scalability**: Add new specialists without modifying existing ones\n",
    "- **Optimization**: Use the most suitable LLM model for each task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÑ Part 2: Workflow Agents\n",
    "\n",
    "ADK provides three main types of workflow agents:\n",
    "\n",
    "### 2.1 SequentialAgent - Sequential Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Define Sub-Agents for Each Pipeline Stage ---\n",
    "GEMINI_MODEL = \"gemini-2.5-flash\"  # Gemini model to use\n",
    "# Information Extractor Agent\n",
    "# Takes the initial document (from user query) and extracts key information.\n",
    "extractor_agent = LlmAgent(\n",
    "    name=\"ExtractorAgent\",\n",
    "    model=GEMINI_MODEL,\n",
    "    instruction=\"\"\"You are a Document Information Extraction Specialist.\n",
    "Based *solely* on the document provided by the user, extract the most important and relevant information.\n",
    "\n",
    "**Your task:**\n",
    "1. Identify key points, important data, dates, names, figures, and main concepts\n",
    "2. Organize the extracted information in a clear and structured manner\n",
    "3. Maintain objectivity and do not add personal interpretations\n",
    "\n",
    "**Output format:**\n",
    "Present the extracted information in clear categories such as:\n",
    "- General Information\n",
    "- Numerical Data/Statistics  \n",
    "- People/Entities Mentioned\n",
    "- Important Dates\n",
    "- Key Content Points\n",
    "\n",
    "Provide *only* the extracted information in an organized format, without additional comments.\"\"\",\n",
    "    description=\"Extracts key information and important data from documents.\",\n",
    "    output_key=\"extracted_information\" # Stores output in state['extracted_information']\n",
    ")\n",
    "\n",
    "# Content Analyzer Agent\n",
    "# Takes the information extracted by the previous agent and provides deep analysis.\n",
    "analyzer_agent = LlmAgent(\n",
    "    name=\"AnalyzerAgent\", \n",
    "    model=GEMINI_MODEL,\n",
    "    instruction=\"\"\"You are an Expert Content Analyst.\n",
    "Your task is to deeply analyze the extracted information and generate valuable insights.\n",
    "\n",
    "**Information to Analyze:**\n",
    "{extracted_information}\n",
    "\n",
    "**Analysis Criteria:**\n",
    "1. **Trends and Patterns:** What trends or patterns emerge from the data?\n",
    "2. **Implications:** What are the most important implications of this information?\n",
    "3. **Relationships:** How do the different elements relate to each other?\n",
    "4. **Opportunities:** What opportunities or risks can be identified?\n",
    "5. **Context:** What does this information mean in the broader context?\n",
    "\n",
    "**Output:**\n",
    "Provide a structured analysis with clear and actionable insights.\n",
    "Focus on the most significant findings that add value to the original document.\n",
    "Present *only* the analysis without additional comments.\"\"\",\n",
    "    description=\"Analyzes extracted information to generate valuable insights.\",\n",
    "    output_key=\"analysis_insights\" # Stores output in state['analysis_insights']\n",
    ")\n",
    "\n",
    "# LinkedIn Post Creator Agent\n",
    "# Takes the extracted information and analysis to create attractive LinkedIn posts.\n",
    "linkedin_creator_agent = LlmAgent(\n",
    "    name=\"LinkedInCreatorAgent\",\n",
    "    model=GEMINI_MODEL,\n",
    "    instruction=\"\"\"You are a LinkedIn Content Marketing Specialist.\n",
    "Your goal is to create attractive and professional LinkedIn posts based on the provided information and analysis.\n",
    "\n",
    "**Extracted Information:**\n",
    "{extracted_information}\n",
    "\n",
    "**Analysis and Insights:**\n",
    "{analysis_insights}\n",
    "\n",
    "**Task:**\n",
    "Create a LinkedIn post that is:\n",
    "1. **Attractive:** Captures attention from the first lines\n",
    "2. **Professional:** Maintains appropriate tone for the professional network\n",
    "3. **Valuable:** Provides useful insights to the audience\n",
    "4. **Actionable:** Includes relevant calls to action\n",
    "5. **Engaging:** Encourages interaction and comments\n",
    "\n",
    "**Post Structure:**\n",
    "- Impactful initial hook (1-2 lines)\n",
    "- Development of main insight (3-4 short paragraphs)\n",
    "- 3-5 key points with appropriate emojis\n",
    "- Final call to action\n",
    "- Relevant hashtags (5-8 hashtags)\n",
    "\n",
    "**Style:**\n",
    "- Use short paragraphs for easy reading\n",
    "- Include emojis strategically\n",
    "- Maintain conversational but professional tone\n",
    "- Ideal length: 200-300 words\n",
    "\n",
    "**Output:**\n",
    "Provide *only* the final post ready to publish on LinkedIn.\"\"\",\n",
    "    description=\"Creates attractive LinkedIn posts based on document extraction and analysis.\",\n",
    "    output_key=\"linkedin_post\" # Stores output in state['linkedin_post']\n",
    ")\n",
    "\n",
    "# --- 2. Create the SequentialAgent ---\n",
    "# This agent orchestrates the pipeline executing the sub_agents in order.\n",
    "document_analysis_pipeline = SequentialAgent(\n",
    "    name=\"DocumentAnalysisPipeline\",\n",
    "    sub_agents=[extractor_agent, analyzer_agent, linkedin_creator_agent],\n",
    "    description=\"Executes a sequence of extraction, analysis and LinkedIn post creation based on documents.\",\n",
    "    # Agents will execute in the provided order: Extractor -> Analyzer -> LinkedIn Creator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "session_service = InMemorySessionService()\n",
    "\n",
    "APP_NAME = \"sequence_agent_example\"\n",
    "USER_ID = \"user_1\"\n",
    "SESSION_ID = \"session_001\" # Using a fixed ID for simplicity\n",
    "\n",
    "# Create the specific session where the conversation will occur\n",
    "session = await session_service.create_session(\n",
    "    app_name=APP_NAME,\n",
    "    user_id=USER_ID,\n",
    "    session_id=SESSION_ID\n",
    ")\n",
    "# Runner: This is the main component that manages interaction with the agent.\n",
    "runner = Runner(agent=document_analysis_pipeline,\n",
    "                app_name=APP_NAME,\n",
    "                session_service=session_service)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test text\n",
    "input_text = \"\"\"\n",
    "Introducing a new, unifying DNA sequence model that advances regulatory variant-effect prediction and promises to shed new light on genome function ‚Äî now available via API.\n",
    "\n",
    "The genome is our cellular instruction manual. It's the complete set of DNA which guides nearly every part of a living organism, from appearance and function to growth and reproduction. Small variations in a genome's DNA sequence can alter an organism's response to its environment or its susceptibility to disease. But deciphering how the genome's instructions are read at the molecular level ‚Äî and what happens when a small DNA variation occurs ‚Äî is still one of biology's greatest mysteries.\n",
    "\n",
    "Today, we introduce AlphaGenome, a new artificial intelligence (AI) tool that more comprehensively and accurately predicts how single variants or mutations in human DNA sequences impact a wide range of biological processes regulating genes. This was enabled, among other factors, by technical advances allowing the model to process long DNA sequences and output high-resolution predictions.\n",
    "\n",
    "To advance scientific research, we're making AlphaGenome available in preview via our AlphaGenome API for non-commercial research, and planning to release the model in the future.\n",
    "\n",
    "We believe AlphaGenome can be a valuable resource for the scientific community, helping scientists better understand genome function, disease biology, and ultimately, drive new biological discoveries and the development of new treatments.\n",
    "\n",
    "How AlphaGenome works\n",
    "Our AlphaGenome model takes a long DNA sequence as input ‚Äî up to 1 million letters, also known as base-pairs ‚Äî and predicts thousands of molecular properties characterising its regulatory activity. It can also score the effects of genetic variants or mutations by comparing predictions of mutated sequences with unmutated ones.\n",
    "\n",
    "Predicted properties include where genes start and where they end in different cell types and tissues, where they get spliced, the amount of RNA being produced, and also which DNA bases are accessible, close to one another, or bound by certain proteins. Training data was sourced from large public consortia including ENCODE, GTEx, 4D Nucleome and FANTOM5, which experimentally measured these properties covering important modalities of gene regulation across hundreds of human and mouse cell types and tissues.\n",
    "\n",
    "\n",
    "Play video\n",
    "Animation showing AlphaGenome taking one million DNA letters as input and predicting diverse molecular properties across different tissues and cell types.\n",
    "\n",
    "The AlphaGenome architecture uses convolutional layers to initially detect short patterns in the genome sequence, transformers to communicate information across all positions in the sequence, and a final series of layers to turn the detected patterns into predictions for different modalities. During training, this computation is distributed across multiple interconnected Tensor Processing Units (TPUs) for a single sequence.\n",
    "\n",
    "This model builds on our previous genomics model, Enformer and is complementary to AlphaMissense, which specializes in categorizing the effects of variants within protein-coding regions. These regions cover 2% of the genome. The remaining 98%, called non-coding regions, are crucial for orchestrating gene activity and contain many variants linked to diseases. AlphaGenome offers a new perspective for interpreting these expansive sequences and the variants within them.\n",
    "\n",
    "AlphaGenome's distinctive features\n",
    "AlphaGenome offers several distinctive features compared to existing DNA sequence models:\n",
    "\n",
    "Long sequence-context at high resolution\n",
    "Our model analyzes up to 1 million DNA letters and makes predictions at the resolution of individual letters. Long sequence context is important for covering regions regulating genes from far away and base-resolution is important for capturing fine-grained biological details.\n",
    "\n",
    "Previous models had to trade off sequence length and resolution, which limited the range of modalities they could jointly model and accurately predict. Our technical advances address this limitation without significantly increasing the training resources ‚Äî training a single AlphaGenome model (without distillation) took four hours and required half of the compute budget used to train our original Enformer model.\n",
    "\n",
    "Comprehensive multimodal prediction\n",
    "By unlocking high resolution prediction for long input sequences, AlphaGenome can predict the most diverse range of modalities. In doing so, AlphaGenome provides scientists with more comprehensive information about the complex steps of gene regulation.\n",
    "\n",
    "Efficient variant scoring\n",
    "In addition to predicting a diverse range of molecular properties, AlphaGenome can efficiently score the impact of a genetic variant on all of these properties in a second. It does this by contrasting predictions of mutated sequences with unmutated ones, and efficiently summarising that contrast using different approaches for different modalities.\n",
    "\n",
    "Novel splice-junction modeling\n",
    "Many rare genetic diseases, such as spinal muscular atrophy and some forms of cystic fibrosis, can be caused by errors in RNA splicing ‚Äî a process where parts of the RNA molecule are removed, or \"spliced out\", and the remaining ends rejoined. For the first time, AlphaGenome can explicitly model the location and expression level of these junctions directly from sequence, offering deeper insights about the consequences of genetic variants on RNA splicing.\n",
    "\n",
    "State-of-the-art performance across benchmarks\n",
    "AlphaGenome achieves state-of-the-art performance across a wide range of genomic prediction benchmarks, such as predicting which parts of the DNA molecule will be in close proximity, whether a genetic variant will increase or decrease expression of a gene, or whether it will change the gene's splicing pattern.\n",
    "\n",
    "\n",
    "Bar graph showing AlphaGenome's relative improvements on selected DNA sequence and variant effect tasks, compared against results for the current best methods in each category.\n",
    "\n",
    "When producing predictions for single DNA sequences, AlphaGenome outperformed the best external models on 22 out of 24 evaluations. And when predicting the regulatory effect of a variant, it matched or exceeded the top-performing external models on 24 out of 26 evaluations.\n",
    "\n",
    "This comparison included models specialized for individual tasks. AlphaGenome was the only model that could jointly predict all of the assessed modalities, highlighting its generality. Read more in our preprint.\n",
    "\n",
    "The benefits of a unifying model\n",
    "AlphaGenome's generality allows scientists to simultaneously explore a variant's impact on a number of modalities with a single API call. This means that scientists can generate and test hypotheses more rapidly, without having to use multiple models to investigate different modalities.\n",
    "\n",
    "Moreover AlphaGenome's strong performance indicates it has learned a relatively general representation of DNA sequence in the context of gene regulation. This makes it a strong foundation for the wider community to build upon. Once the model is fully released, scientists will be able to adapt and fine-tune it on their own datasets to better tackle their unique research questions.\n",
    "\n",
    "Finally, this approach provides a flexible and scalable architecture for the future. By extending the training data, AlphaGenome's capabilities could be extended to yield better performance, cover more species, or include additional modalities to make the model even more comprehensive.\n",
    "\n",
    ""\n",
    "It's a milestone for the field. For the first time, we have a single model that unifies long-range context, base-level precision and state-of-the-art performance across a whole spectrum of genomic tasks.\n",
    "\n",
    "Dr. Caleb Lareau, Memorial Sloan Kettering Cancer Center\n",
    "\n",
    "A powerful research tool\n",
    "AlphaGenome's predictive capabilities could help several research avenues:\n",
    "\n",
    "Disease understanding: By more accurately predicting genetic disruptions, AlphaGenome could help researchers pinpoint the potential causes of disease more precisely, and better interpret the functional impact of variants linked to certain traits, potentially uncovering new therapeutic targets. We think the model is especially suitable for studying rare variants with potentially large effects, such as those causing rare Mendelian disorders.\n",
    "Synthetic biology: Its predictions could be used to guide the design of synthetic DNA with specific regulatory function ‚Äî for example, only activating a gene in nerve cells but not muscle cells.\n",
    "Fundamental research: It could accelerate our understanding of the genome by assisting in mapping its crucial functional elements and defining their roles, identifying the most essential DNA instructions for regulating a specific cell type's function.\n",
    "For example, we used AlphaGenome to investigate the potential mechanism of a cancer-associated mutation. In an existing study of patients with T-cell acute lymphoblastic leukemia (T-ALL), researchers observed mutations at particular locations in the genome. Using AlphaGenome, we predicted that the mutations would activate a nearby gene called TAL1 by introducing a MYB DNA binding motif, which replicated the known disease mechanism and highlighted AlphaGenome's ability to link specific non-coding variants to disease genes.\n",
    "\n",
    ""\n",
    "AlphaGenome will be a powerful tool for the field. Determining the relevance of different non-coding variants can be extremely challenging, particularly to do at scale. This tool will provide a crucial piece of the puzzle, allowing us to make better connections to understand diseases like cancer.\n",
    "\n",
    "Professor Marc Mansour, University College London\n",
    "\n",
    "Current limitations\n",
    "AlphaGenome marks a significant step forward, but it's important to acknowledge its current limitations.\n",
    "\n",
    "Like other sequence-based models, accurately capturing the influence of very distant regulatory elements, like those over 100,000 DNA letters away, is still an ongoing challenge. Another priority for future work is further increasing the model's ability to capture cell- and tissue-specific patterns.\n",
    "\n",
    "We haven't designed or validated AlphaGenome for personal genome prediction, a known challenge for AI models. Instead, we focused more on characterising the performance on individual genetic variants. And while AlphaGenome can predict molecular outcomes, it doesn't give the full picture of how genetic variations lead to complex traits or diseases. These often involve broader biological processes, like developmental and environmental factors, that are beyond the direct scope of our model.\n",
    "\n",
    "We're continuing to improve our models and gathering feedback to help us address these gaps.\"\"\"\n",
    "\n",
    "# Execute\n",
    "\n",
    "await call_agent_async_with_full_trace(input_text,\n",
    "                        runner=runner,\n",
    "                        user_id=USER_ID,\n",
    "                        session_id=SESSION_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 ParallelAgent - Parallel Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.adk.tools import google_search\n",
    "GEMINI_MODEL = \"gemini-2.5-flash\"\n",
    "# Example 2: Parallel Research\n",
    "print(\"\\n=== Example: ParallelAgent ===\")\n",
    "# Part of agent.py --> Follow https://google.github.io/adk-docs/get-started/quickstart/ to learn the configuration\n",
    "# --- 1. Define Research Sub-Agents (to execute in parallel) ---\n",
    "\n",
    "# Researcher 1: Consumer Trends\n",
    "consumer_researcher = LlmAgent(\n",
    "    name=\"ConsumerTrendsResearcher\",\n",
    "    model=GEMINI_MODEL,\n",
    "    instruction=\"\"\"You are an AI Research Assistant specialized in consumer behavior.\n",
    "Research the latest 'e-commerce consumer trends' and online shopping patterns.\n",
    "Use the provided Google Search tool.\n",
    "Summarize your key findings concisely.\n",
    "Provide *only* the summary.\n",
    "\"\"\",\n",
    "    description=\"Researches consumer trends and shopping patterns in e-commerce.\",\n",
    "    tools=[google_search],\n",
    "    # Store result in state for the fusion agent\n",
    "    output_key=\"consumer_trends_result\"\n",
    ")\n",
    "\n",
    "# Researcher 2: Competitor Analysis\n",
    "competitor_researcher = LlmAgent(\n",
    "    name=\"CompetitorResearcher\",\n",
    "    model=GEMINI_MODEL,\n",
    "    instruction=\"\"\"You are an AI Research Assistant specialized in competitive analysis.\n",
    "Research the 'main e-commerce competitors' and their successful strategies.\n",
    "Use the provided Google Search tool.\n",
    "Summarize your key findings concisely.\n",
    "Provide *only* the summary.\n",
    "\"\"\",\n",
    "    description=\"Researches main competitors and successful strategies in e-commerce.\",\n",
    "    tools=[google_search],\n",
    "    # Store result in state for the fusion agent\n",
    "    output_key=\"competitors_result\"\n",
    ")\n",
    "\n",
    "# Researcher 3: Emerging Technologies\n",
    "technology_researcher = LlmAgent(\n",
    "    name=\"TechnologyResearcher\",\n",
    "    model=GEMINI_MODEL,\n",
    "    instruction=\"\"\"You are an AI Research Assistant specialized in retail technology.\n",
    "Research 'emerging technologies in e-commerce' like AI, AR/VR, and automation.\n",
    "Use the provided Google Search tool.\n",
    "Summarize your key findings concisely.\n",
    "Provide *only* the summary.\n",
    "\"\"\",\n",
    "    description=\"Researches emerging technologies and innovations in e-commerce.\",\n",
    "    tools=[google_search],\n",
    "    # Store result in state for the fusion agent\n",
    "    output_key=\"technologies_result\"\n",
    ")\n",
    "\n",
    "# --- 2. Create the ParallelAgent (Execute researchers concurrently) ---\n",
    "# This agent orchestrates the concurrent execution of the researchers.\n",
    "# It finishes once all researchers have completed and stored their results in state.\n",
    "parallel_research_agent = ParallelAgent(\n",
    "    name=\"ParallelEcommerceResearchAgent\",\n",
    "    sub_agents=[consumer_researcher, competitor_researcher, technology_researcher],\n",
    "    description=\"Executes multiple research agents in parallel to gather market information.\"\n",
    ")\n",
    "\n",
    "# --- 3. Define the Fusion Agent (Runs *after* parallel agents) ---\n",
    "# This agent takes the results stored in session state by the parallel agents\n",
    "# and synthesizes them into a single, structured response with attributions.\n",
    "fusion_agent = LlmAgent(\n",
    "    name=\"SynthesisAgent\",\n",
    "    model=GEMINI_MODEL,  # Or potentially a more powerful model if needed for synthesis\n",
    "    instruction=\"\"\"You are an AI Assistant responsible for combining research findings into a structured market report.\n",
    "\n",
    "Your main task is to synthesize the following research summaries, clearly attributing findings to their source areas. Structure your response using headings for each topic. Ensure the report is coherent and integrates key points smoothly.\n",
    "\n",
    "**Crucial: Your complete response MUST be based *exclusively* on the information provided in the 'Input Summaries' below. DO NOT add external knowledge, facts or details that are not present in these specific summaries.**\n",
    "\n",
    "**Input Summaries:**\n",
    "\n",
    "*   **Consumer Trends:**\n",
    "    {consumer_trends_result}\n",
    "\n",
    "*   **Competitor Analysis:**\n",
    "    {competitors_result}\n",
    "\n",
    "*   **Emerging Technologies:**\n",
    "    {technologies_result}\n",
    "\n",
    "**Output Format:**\n",
    "\n",
    "## E-commerce Market Analysis: Recent Findings\n",
    "\n",
    "### Consumer Trends\n",
    "(Based on findings from ConsumerTrendsResearcher)\n",
    "[Synthesize and elaborate *only* on the consumer trends input summary provided above.]\n",
    "\n",
    "### Competitive Landscape\n",
    "(Based on findings from CompetitorResearcher)\n",
    "[Synthesize and elaborate *only* on the competitors input summary provided above.]\n",
    "\n",
    "### Technological Innovations\n",
    "(Based on findings from TechnologyResearcher)\n",
    "[Synthesize and elaborate *only* on the technologies input summary provided above.]\n",
    "\n",
    "### General Conclusion\n",
    "[Provide a brief concluding statement (1-2 sentences) that connects *only* the findings presented above.]\n",
    "\n",
    "Provide *only* the structured report following this format. Do not include introductory or concluding phrases outside this structure, and strictly adhere to using only the content from the provided input summaries.\n",
    "\"\"\",\n",
    "    description=\"Combines research findings from parallel agents into a structured and cited report, strictly based on provided inputs.\",\n",
    "    # No tools needed for fusion\n",
    "    # No output_key needed here, as its direct response is the final output of the sequence\n",
    ")\n",
    "\n",
    "# --- 4. Create the SequentialAgent (Orchestrates overall flow) ---\n",
    "# This is the main agent that will be executed. It first runs the ParallelAgent\n",
    "# to populate the state, then runs the FusionAgent to produce the final output.\n",
    "sequential_pipeline_agent = SequentialAgent(\n",
    "    name=\"ResearchAndSynthesisPipeline\",\n",
    "    # Execute parallel research first, then fusion\n",
    "    sub_agents=[parallel_research_agent, fusion_agent],\n",
    "    description=\"Coordinates parallel research and synthesizes results into market analysis.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "session_service = InMemorySessionService()\n",
    "\n",
    "APP_NAME = \"parallel_agent_example\"\n",
    "USER_ID = \"user_1\"\n",
    "SESSION_ID = \"session_001\" # Using a fixed ID for simplicity\n",
    "\n",
    "# Create the specific session where the conversation will occur\n",
    "session = await session_service.create_session(\n",
    "    app_name=APP_NAME,\n",
    "    user_id=USER_ID,\n",
    "    session_id=SESSION_ID\n",
    ")\n",
    "# Runner: This is the main component that manages interaction with the agent.\n",
    "runner = Runner(agent=sequential_pipeline_agent,\n",
    "                app_name=APP_NAME,\n",
    "                session_service=session_service)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test text\n",
    "input_text = \"\"\"Research the latest e-commerce trends.\n",
    "Provide a complete and structured market analysis based on the information gathered.\n",
    "\"\"\"\n",
    "\n",
    "# Execute\n",
    "\n",
    "await call_agent_async_with_full_trace(input_text,\n",
    "                        runner=runner,\n",
    "                        user_id=USER_ID,\n",
    "                        session_id=SESSION_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 LoopAgent - Iterative Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.adk.tools.tool_context import ToolContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 3: Iterative Content Refinement\n",
    "\n",
    "# Tool to exit the loop\n",
    "def exit_loop(tool_context: ToolContext):\n",
    "  \"\"\"Call this function ONLY when the critique indicates no further changes are needed, signaling the iterative process should end.\"\"\"\n",
    "  print(f\"  [Tool Call] exit_loop triggered by {tool_context.agent_name}\")\n",
    "  tool_context.actions.escalate = True\n",
    "  # Return empty dict as tools should typically return JSON-serializable output\n",
    "  return {}\n",
    "\n",
    "print(\"\\n=== Example: LoopAgent ===\")\n",
    "\n",
    "# Writer agent\n",
    "writer = LlmAgent(\n",
    "    name=\"Writer\",\n",
    "    model=\"gemini-1.5-flash\",\n",
    "    instruction=(\n",
    "        \"Improve the current text based on the critiques received. \"\n",
    "        \"If there is no previous text, generate an initial one on the given topic.\"\n",
    "    ),\n",
    "    output_key=\"current_text\"\n",
    ")\n",
    "\n",
    "# Critic agent\n",
    "critic = LlmAgent(\n",
    "    name=\"Critic\",\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    instruction=(\n",
    "        \"Review in great detail and critique the following text 'current_text' \"\n",
    "        \"and provide constructive criticism to improve it. \"\n",
    "        \"If the text is excellent and needs no improvement, say exactly: \"\n",
    "        \"'No further improvements required.' and call the exit_loop tool. \"\n",
    "        \"Otherwise, provide specific suggestions to improve the text.\"\n",
    "    ),\n",
    "    tools=[exit_loop],\n",
    "    output_key=\"critique\"\n",
    ")\n",
    "\n",
    "\n",
    "# Refinement loop\n",
    "refinement_loop = LoopAgent(\n",
    "    name=\"RefinementLoop\",\n",
    "    sub_agents=[writer, critic],\n",
    "    max_iterations=6  # Maximum 6 iterations\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_service = InMemorySessionService()\n",
    "\n",
    "APP_NAME = \"loop_agent_example\"\n",
    "USER_ID = \"user_1\"\n",
    "SESSION_ID = \"session_001\" # Using a fixed ID for simplicity\n",
    "\n",
    "# Create the specific session where the conversation will occur\n",
    "session = await session_service.create_session(\n",
    "    app_name=APP_NAME,\n",
    "    user_id=USER_ID,\n",
    "    session_id=SESSION_ID\n",
    ")\n",
    "# Runner: This is the main component that manages interaction with the agent.\n",
    "runner = Runner(agent=refinement_loop,\n",
    "                app_name=APP_NAME,\n",
    "                session_service=session_service)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await call_agent_async_with_full_trace(\n",
    "    query=\"Write a short poem about the moon and stars.\",\n",
    "    runner=runner,\n",
    "    user_id=USER_ID,\n",
    "    session_id=SESSION_ID\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üåç Part 3: Complete Example - Travel Planning System\n",
    "\n",
    "Now we'll build a complex system that combines all concepts:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Part 4: Advanced Orchestration Patterns\n",
    "\n",
    "### 5.1 Hybrid Orchestration (Combine Sequential, Parallel and Loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Advanced Pattern: Hybrid Orchestration ===\")\n",
    "\n",
    "# Example: Document analysis system with multiple passes\n",
    "\n",
    "# Parallel extractors for different types of information\n",
    "entity_extractor = LlmAgent(\n",
    "    name=\"EntityExtractor\",\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    instruction=\"Extract all people, places and organizations mentioned.\",\n",
    "    output_key=\"entities\"\n",
    ")\n",
    "\n",
    "date_extractor = LlmAgent(\n",
    "    name=\"DateExtractor\",\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    instruction=\"Extract all dates and temporal events mentioned.\",\n",
    "    output_key=\"dates\"\n",
    ")\n",
    "\n",
    "number_extractor = LlmAgent(\n",
    "    name=\"NumberExtractor\",\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    instruction=\"Extract all numbers, quantities and important metrics.\",\n",
    "    output_key=\"metrics\"\n",
    ")\n",
    "\n",
    "# Parallel extraction\n",
    "parallel_extraction = ParallelAgent(\n",
    "    name=\"ParallelExtraction\",\n",
    "    sub_agents=[entity_extractor, date_extractor, number_extractor]\n",
    ")\n",
    "\n",
    "# Validator that checks quality\n",
    "validator = LlmAgent(\n",
    "    name=\"Validator\",\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    instruction=(\n",
    "        \"Review the extracted information in 'entities', 'dates' and 'metrics'. \"\n",
    "        \"Entities: {entities} \" \n",
    "        \"Dates: {dates}\"\n",
    "        \"Metrics: {metrics}. \"\n",
    "        \"If important information is missing or there are inconsistencies, indicate what to improve. \"\n",
    "        \"If everything is complete and correct, say: 'Extraction complete and valid'.\"\n",
    "    ),\n",
    "    output_key=\"validation\"\n",
    ")\n",
    "\n",
    "# Improver that refines based on validation\n",
    "improver = LlmAgent(\n",
    "    name=\"Improver\",\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    instruction=(\n",
    "        \"If validation indicates problems, improve the extraction. \"\n",
    "        \"If it says 'Extraction complete and valid', make no changes.\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Improvement loop\n",
    "improvement_loop = LoopAgent(\n",
    "    name=\"ImprovementLoop\",\n",
    "    sub_agents=[validator, improver],\n",
    "    max_iterations=6\n",
    ")\n",
    "\n",
    "# Final report generator\n",
    "report_generator = LlmAgent(\n",
    "    name=\"ReportGenerator\",\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    instruction=(\n",
    "        \"Generate a structured report with all extracted information: \"\n",
    "        \"entities, dates and metrics. Format professionally.\"\n",
    "        \"Include clear sections for each type of extracted information. \"\n",
    "        \"Extracted entities: {entities}, \"\n",
    "        \"Extracted dates: {dates}, \"\n",
    "        \"Extracted metrics: {metrics}. \"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Complete hybrid pipeline\n",
    "analysis_system = SequentialAgent(\n",
    "    name=\"DocumentAnalysisSystem\",\n",
    "    sub_agents=[\n",
    "        parallel_extraction,  # 1. Parallel extraction\n",
    "        improvement_loop,     # 2. Validation and improvement loop\n",
    "        report_generator      # 3. Final report generation\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_service = InMemorySessionService()\n",
    "\n",
    "APP_NAME = \"complete_workflow_agent_example\"\n",
    "USER_ID = \"user_1\"\n",
    "SESSION_ID = \"session_001\" # Using a fixed ID for simplicity\n",
    "\n",
    "# Create the specific session where the conversation will occur\n",
    "session = await session_service.create_session(\n",
    "    app_name=APP_NAME,\n",
    "    user_id=USER_ID,\n",
    "    session_id=SESSION_ID\n",
    ")\n",
    "# Runner: This is the main component that manages interaction with the agent.\n",
    "runner = Runner(agent=analysis_system,\n",
    "                app_name=APP_NAME,\n",
    "                session_service=session_service)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = \"\"\"\n",
    "Apple Inc. announced on January 15, 2024 record results with revenue \n",
    "of $123.9 billion, a 15% increase from the previous year. \n",
    "Tim Cook, Apple's CEO, highlighted the success of the iPhone 15 in Asian markets, \n",
    "especially in China where sales grew 22%. The company \n",
    "plans to open 50 new stores in 2024, including locations in \n",
    "Mumbai, Paris and S√£o Paulo. The launch event is scheduled \n",
    "for September 9, 2024 in Cupertino.\n",
    "\"\"\"\n",
    "await call_agent_async_with_full_trace(document,\n",
    "                        runner=runner,\n",
    "                        user_id=USER_ID,\n",
    "                        session_id=SESSION_ID\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Practical Exercises\n",
    "\n",
    "### Exercise 1: Data Analysis Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Exercise 2: Data Analysis Pipeline ===\")\n",
    "\n",
    "# TODO: Create a pipeline that:\n",
    "# 1. Load data (simulated)\n",
    "# 2. Execute 3 types of analysis in parallel\n",
    "# 3. Combine the results\n",
    "# 4. Create an executive report\n",
    "\n",
    "# Your code here:\n",
    "# data_loader = LlmAgent(...)\n",
    "# statistical_analyzer = LlmAgent(...)\n",
    "# trends_analyzer = LlmAgent(...)\n",
    "# anomaly_analyzer = LlmAgent(...)\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö Best Practices and Tips\n",
    "\n",
    "### 1. Agent Design\n",
    "- **Specialization**: Each agent should have a clear and specific purpose\n",
    "- **Communication**: Use `output_key` to pass information between agents\n",
    "- **Models**: Use simpler models for simple tasks (saves costs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Debugging and Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable detailed logging\n",
    "logging.getLogger(\"google.adk\").setLevel(logging.DEBUG)\n",
    "\n",
    "# Capture events for debugging\n",
    "async def debug_execution(agent, input_text):\n",
    "    runner = Runner(agent=agent, session_service=InMemorySessionService())\n",
    "    \n",
    "    events = []\n",
    "    async for event in runner.run_async_stream(input_text=input_text):\n",
    "        events.append({\n",
    "            \"type\": event.type,\n",
    "            \"agent\": getattr(event.data, 'agent_name', 'N/A'),\n",
    "            \"timestamp\": event.timestamp\n",
    "        })\n",
    "        \n",
    "    # Analyze event flow\n",
    "    for e in events:\n",
    "        print(f\"{e['timestamp']}: {e['type']} - {e['agent']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Conclusion\n",
    "\n",
    "Congratulations! You have learned to:\n",
    "- ‚úÖ Create sequential pipelines with `SequentialAgent`\n",
    "- ‚úÖ Execute tasks in parallel with `ParallelAgent`\n",
    "- ‚úÖ Implement iterative refinement with `LoopAgent`\n",
    "- ‚úÖ Build dynamic routing with manager agents\n",
    "- ‚úÖ Combine patterns for complex systems\n",
    "- ‚úÖ Create custom agents with advanced logic\n",
    "\n",
    "\n",
    "## üìñ Additional Resources\n",
    "\n",
    "- [Official ADK Documentation](https://google.github.io/adk-docs/)\n",
    "- [ADK Examples on GitHub](https://github.com/google/adk-samples)\n",
    "- [Workflow Agents Guide](https://google.github.io/adk-docs/agents/workflow-agents/)\n",
    "- [Multi-Agent Systems in ADK](https://google.github.io/adk-docs/agents/multi-agents/)\n",
    "\n",
    "---\n",
    "\n",
    "**Thank you for completing Class 5!** üéâ\n",
    "\n",
    "Now you have the power to create sophisticated multi-agent systems. Time to build something incredible!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}